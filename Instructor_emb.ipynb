{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751835a3-2002-462a-b812-f34022afdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "import torch\n",
    "import collections\n",
    "import imodelsx\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd9c99-ba59-46d8-964e-2d44f06f41f5",
   "metadata": {},
   "source": [
    "## EDA of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3a172b-9b26-4fa1-9598-5fd24dc2e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#approach one using imodelsx\n",
    "SST2 =imodelsx.data.load_huggingface_dataset('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba777707-1a41-4454-b896-e8836c87b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ds\n",
    "sst2 = datasets.load_dataset('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15d2e18-e340-4723-b1a4-f9628756cf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['idx', 'sentence', 'label'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['idx', 'sentence', 'label'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['idx', 'sentence', 'label'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d96240-37e6-4e3e-92b0-de4b2fa39480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['idx', 'sentence', 'label'],\n",
       " 'validation': ['idx', 'sentence', 'label'],\n",
       " 'test': ['idx', 'sentence', 'label']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(sst2)\n",
    "sst2.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "540b8eaa-28ed-4c85-8c98-8fd94f9dc674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 67349, 'validation': 872, 'test': 1821}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b9d47eb-c810-423c-a12a-090d3858fb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hide new secretions from the parental units ',\n",
       " 'contains no wit , only labored gags ',\n",
       " 'that loves its characters and communicates something rather beautiful about human nature ',\n",
       " 'remains utterly satisfied to remain the same throughout ',\n",
       " 'on the worst revenge-of-the-nerds clichÃ©s the filmmakers could dredge up ',\n",
       " \"that 's far too tragic to merit such superficial treatment \",\n",
       " 'demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . ',\n",
       " 'of saucy ',\n",
       " \"a depressed fifteen-year-old 's suicidal poetry \",\n",
       " \"are more deeply thought through than in most ` right-thinking ' films \"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample of first 10 reviews\n",
    "sst2['train']['sentence'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e08b9a3-4742-4aa5-b2ff-e10ca7553c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contains no wit , only labored gags '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2['train']['sentence'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9eab18-09eb-4f34-960f-8da15472c064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uneasy mishmash of styles and genres .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2['test']['sentence'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be7f73b-c3e6-474d-bb82-f52244fd3501",
   "metadata": {},
   "source": [
    "## Compute embedding of first 10 sentence; no further training needed by ðŸ‘¨â€ðŸ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8733338-6e89-4e25-bd1a-70842cb6063d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "#dir(INSTRUCTOR)\n",
    "model = INSTRUCTOR('hkunlp/instructor-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5222b5fc-46ff-4f1a-9f83-74ec0b5f3ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "[[ 0.02479305 -0.01686814  0.02904831 ...  0.00310309 -0.05065686\n",
      "  -0.00042309]\n",
      " [-0.02396188 -0.00445384  0.05356156 ... -0.00792792 -0.03100418\n",
      "   0.03949679]\n",
      " [-0.04197229 -0.00706967  0.04467202 ... -0.00451127 -0.01771464\n",
      "   0.04970837]\n",
      " ...\n",
      " [-0.0043071  -0.01626733  0.00555013 ... -0.02947796 -0.02224189\n",
      "   0.02196053]\n",
      " [-0.0187378  -0.01896087  0.05475057 ...  0.02185187 -0.02786592\n",
      "   0.01402784]\n",
      " [-0.03885051 -0.01989633  0.05630855 ...  0.02359127 -0.04830608\n",
      "   0.03353149]]\n"
     ]
    }
   ],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "model = INSTRUCTOR('hkunlp/instructor-base')\n",
    "sentence = sst2['train']['sentence'][0:10]\n",
    "#instruction = \"Sentiment classification\"\n",
    "embeddings = model.encode(sentence)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcac4c-296f-4d1f-9f12-fe01ba5d9ac6",
   "metadata": {},
   "source": [
    "## Calculate Similarity of the initial two -group of five- sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b2ca0b-2b6d-480c-8a27-5a84bd6fda81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78156936 0.7758671  0.80380815 0.7702233  0.7685855 ]\n",
      " [0.8368263  0.80808187 0.81879485 0.826748   0.8006947 ]\n",
      " [0.80458146 0.8399097  0.8168999  0.82596534 0.84078974]\n",
      " [0.7902657  0.82497215 0.81833506 0.800483   0.7910638 ]\n",
      " [0.83194566 0.8474531  0.78426355 0.7815983  0.84800655]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sentences_a = sst2['train']['sentence'][0:5]\n",
    "sentences_b = sst2['train']['sentence'][5:10]\n",
    "embeddings_a = model.encode(sentences_a)\n",
    "embeddings_b = model.encode(sentences_b)\n",
    "similarities = cosine_similarity(embeddings_a,embeddings_b)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1516c7-52a3-44a8-87a1-e81ea03e66c8",
   "metadata": {},
   "source": [
    "## Feture importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10666f87-cb1f-42fc-ab2e-1ead847cf0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: [CLS], Impact: 0.15352243185043335\n",
      "Token: hide, Impact: 0.14318251609802246\n",
      "Token: new, Impact: 0.14095744490623474\n",
      "Token: secret, Impact: 0.1431151032447815\n",
      "Token: ##ions, Impact: 0.14290404319763184\n",
      "Token: from, Impact: 0.14425644278526306\n",
      "Token: the, Impact: 0.14314311742782593\n",
      "Token: parental, Impact: 0.1402343213558197\n",
      "Token: units, Impact: 0.14379602670669556\n",
      "Token: [SEP], Impact: 0.13814139366149902\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [CLS], Impact: 0.14500880241394043\n",
      "Token: contains, Impact: 0.14539161324501038\n",
      "Token: no, Impact: 0.1486915647983551\n",
      "Token: wit, Impact: 0.14625900983810425\n",
      "Token: ,, Impact: 0.13883653283119202\n",
      "Token: only, Impact: 0.14647403359413147\n",
      "Token: labor, Impact: 0.14709559082984924\n",
      "Token: ##ed, Impact: 0.14947932958602905\n",
      "Token: gag, Impact: 0.14847341179847717\n",
      "Token: ##s, Impact: 0.14475280046463013\n",
      "Token: [SEP], Impact: 0.15841126441955566\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [CLS], Impact: 0.14695534110069275\n",
      "Token: that, Impact: 0.14577537775039673\n",
      "Token: loves, Impact: 0.14343222975730896\n",
      "Token: its, Impact: 0.14295372366905212\n",
      "Token: characters, Impact: 0.13717660307884216\n",
      "Token: and, Impact: 0.13080257177352905\n",
      "Token: communicate, Impact: 0.13545161485671997\n",
      "Token: ##s, Impact: 0.1401258409023285\n",
      "Token: something, Impact: 0.1402132511138916\n",
      "Token: rather, Impact: 0.14110177755355835\n",
      "Token: beautiful, Impact: 0.13926130533218384\n",
      "Token: about, Impact: 0.14124265313148499\n",
      "Token: human, Impact: 0.14028844237327576\n",
      "Token: nature, Impact: 0.14426550269126892\n",
      "Token: [SEP], Impact: 0.16883540153503418\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [CLS], Impact: 0.15366140007972717\n",
      "Token: remains, Impact: 0.14712873101234436\n",
      "Token: utterly, Impact: 0.14539876580238342\n",
      "Token: satisfied, Impact: 0.14516472816467285\n",
      "Token: to, Impact: 0.14750736951828003\n",
      "Token: remain, Impact: 0.14673495292663574\n",
      "Token: the, Impact: 0.14445742964744568\n",
      "Token: same, Impact: 0.14370250701904297\n",
      "Token: throughout, Impact: 0.1467532217502594\n",
      "Token: [SEP], Impact: 0.16690340638160706\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [PAD], Impact: 0.1437567174434662\n",
      "Token: [CLS], Impact: 0.14330831170082092\n",
      "Token: on, Impact: 0.13855242729187012\n",
      "Token: the, Impact: 0.14147868752479553\n",
      "Token: worst, Impact: 0.13437610864639282\n",
      "Token: revenge, Impact: 0.13804373145103455\n",
      "Token: -, Impact: 0.13753944635391235\n",
      "Token: of, Impact: 0.13736453652381897\n",
      "Token: -, Impact: 0.1377195417881012\n",
      "Token: the, Impact: 0.13743847608566284\n",
      "Token: -, Impact: 0.14131826162338257\n",
      "Token: ne, Impact: 0.14028912782669067\n",
      "Token: ##rds, Impact: 0.1391099989414215\n",
      "Token: cl, Impact: 0.13825470209121704\n",
      "Token: ##iche, Impact: 0.13317137956619263\n",
      "Token: ##s, Impact: 0.13844451308250427\n",
      "Token: the, Impact: 0.13732224702835083\n",
      "Token: filmmakers, Impact: 0.14889508485794067\n",
      "Token: could, Impact: 0.13659191131591797\n",
      "Token: dr, Impact: 0.13708537817001343\n",
      "Token: ##edge, Impact: 0.13539141416549683\n",
      "Token: up, Impact: 0.1405428946018219\n",
      "Token: [SEP], Impact: 0.18237963318824768\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Define your sentences\n",
    "sentences_a = sst2['train']['sentence'][0:5]\n",
    "sentences_b = sst2['train']['sentence'][5:10]\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "encoded_group1 = tokenizer(sentences_a, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "encoded_group2 = tokenizer(sentences_b, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Calculate baseline similarity\n",
    "with torch.no_grad():\n",
    "    output_group1 = model(**encoded_group1).last_hidden_state\n",
    "    output_group2 = model(**encoded_group2).last_hidden_state\n",
    "\n",
    "    # Assuming you want to calculate cosine similarity, you can use torch's cosine similarity function\n",
    "    similarity_score = torch.nn.functional.cosine_similarity(output_group1.mean(dim=1), output_group2.mean(dim=1), dim=1).mean()\n",
    "\n",
    "# Now, perturb tokens and calculate similarity for each perturbed sentence\n",
    "for sentence_index in range(len(sentences_a)):\n",
    "    for token_index in range(len(encoded_group1[\"input_ids\"][sentence_index])):\n",
    "        # Create a copy of the original input\n",
    "        perturbed_input = encoded_group1[\"input_ids\"].clone()\n",
    "\n",
    "        # Replace the token with a special token or padding token\n",
    "        perturbed_input[sentence_index][token_index] = tokenizer.pad_token_id\n",
    "\n",
    "        # Calculate similarity for the perturbed input\n",
    "        with torch.no_grad():\n",
    "            perturbed_output = model(input_ids=perturbed_input).last_hidden_state\n",
    "            perturbed_similarity = torch.nn.functional.cosine_similarity(perturbed_output.mean(dim=1), output_group2.mean(dim=1), dim=1).mean()\n",
    "\n",
    "        # Calculate the impact of this token on similarity\n",
    "        impact = similarity_score - perturbed_similarity\n",
    "\n",
    "        # Print or store the token and its impact\n",
    "        print(f\"Token: {tokenizer.decode(encoded_group1['input_ids'][sentence_index][token_index])}, Impact: {impact.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd70a18b-6d4b-4cfd-9b82-700350956f08",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m d \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, text_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([sentences_a, sentences_b]):\n\u001b[0;32m----> 8\u001b[0m     texts \u001b[38;5;241m=\u001b[39m \u001b[43mimodelsx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_ngrams_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mngrams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_ngrams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(texts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/envs/ali-ml/lib/python3.10/site-packages/imodelsx/util.py:46\u001b[0m, in \u001b[0;36mgenerate_ngrams_list\u001b[0;34m(sentence, ngrams, tokenizer_ngrams, all_ngrams, parsing, nlp_chunks, pad_starting_ngrams, pad_ending_ngrams, min_frequency)\u001b[0m\n\u001b[1;32m     43\u001b[0m     tokenizer_ngrams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# unigrams\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m unigrams_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokenizer_ngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     48\u001b[0m     seqs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m unigrams_list\n",
      "File \u001b[0;32m~/anaconda3/envs/ali-ml/lib/python3.10/site-packages/imodelsx/util.py:43\u001b[0m, in \u001b[0;36mgenerate_ngrams_list.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     40\u001b[0m seqs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     tokenizer_ngrams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# unigrams\u001b[39;00m\n\u001b[1;32m     46\u001b[0m unigrams_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tokenizer_ngrams(sentence)]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "with torch.no_grad():\n",
    "    # generate ngrams up to trigrams\n",
    "    sentences_a = sst2['train']['sentence'][0:5]\n",
    "    sentences_b = sst2['train']['sentence'][5:10]\n",
    "    d = collections.defaultdict(list)\n",
    "    for i, text_i in enumerate([sentences_a, sentences_b]):\n",
    "        texts = imodelsx.util.generate_ngrams_list(text_i, ngrams=3, all_ngrams=True)\n",
    "        inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        outputs = model(**inputs).last_hidden_state.detach().cpu().numpy()\n",
    "        embs = np.mean(outputs, axis=1).squeeze()\n",
    "        embs_mean = np.mean(embs, axis=0)\n",
    "\n",
    "        d['texts'].append(texts)\n",
    "        d['embs'].append(embs)\n",
    "        d['embs_mean'].append(embs_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe862024-96a9-4822-a906-93f59ac4344e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf3db6-2607-4be4-b52f-aa15551e4823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561cdc7d-ff9c-4700-b56c-0f7a8febb1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c778718-5a6a-44de-a02b-429bb9b8bb6e",
   "metadata": {},
   "source": [
    "## modified code to take care of the feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5f8ff4b-c1a7-4d96-9656-67e86a6c64a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "model = INSTRUCTOR('hkunlp/instructor-large')\n",
    "sentences_a = sst2['train']['sentence'][0:10]\n",
    "sentences_b = sst2['train']['sentence'][10:20]\n",
    "\n",
    "def extract_ngrams(sentence, n):\n",
    "    tokens = sentence.split()\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "    return [' '.join(gram) for gram in ngrams_list]\n",
    "\n",
    "similarities = []\n",
    "\n",
    "for sentence_a in sentences_a:\n",
    "    for sentence_b in sentences_b:\n",
    "        embeddings_a = model.encode(sentence_a)\n",
    "        embeddings_b = model.encode(sentence_b)\n",
    "        similarity = cosine_similarity(embeddings_a.reshape(1, -1), embeddings_b.reshape(1, -1))[0][0]\n",
    "        \n",
    "        # Perform n-gram averaging\n",
    "        n = 2  # You can adjust the n-gram size\n",
    "        ngrams_a = extract_ngrams(sentence_a, n)\n",
    "        ngrams_b = extract_ngrams(sentence_b, n)\n",
    "        \n",
    "        # Calculate the importance of common n-grams\n",
    "        common_ngrams = set(ngrams_a) & set(ngrams_b)\n",
    "        ngram_importance = {ngram: ngrams_a.count(ngram) + ngrams_b.count(ngram) for ngram in common_ngrams}\n",
    "        \n",
    "        similarities.append((similarity, ngram_importance))\n",
    "\n",
    "# Now you have a list of tuples containing similarity scores and n-gram importance dictionaries for each pair of sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42b0abab-0464-4b53-b71a-fa33ba5db08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5Model were not initialized from the model checkpoint at hkunlp/instructor-large and are newly initialized: ['decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.final_layer_norm.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You have to specify either decoder_input_ids or decoder_inputs_embeds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m texts \u001b[38;5;241m=\u001b[39m imodelsx\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mgenerate_ngrams_list(sentence, ngrams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, all_ngrams\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(texts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     16\u001b[0m embs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(outputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     17\u001b[0m embs_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(embs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ali-ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/ali-ml/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1497\u001b[0m, in \u001b[0;36mT5Model.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1494\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1497\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/ali-ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/ali-ml/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:987\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m     err_msg_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minput_ids or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: You have to specify either decoder_input_ids or decoder_inputs_embeds"
     ]
    }
   ],
   "source": [
    "# Initialize the defaultdict\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hkunlp/instructor-large\")\n",
    "model = AutoModel.from_pretrained(\"hkunlp/instructor-large\")\n",
    "\n",
    "\n",
    "d = collections.defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # generate ngrams up to trigrams\n",
    "    for i, sentence_list in enumerate([sentences_a, sentences_b]):\n",
    "        for sentence in sentence_list:\n",
    "            texts = imodelsx.util.generate_ngrams_list(sentence, ngrams=3, all_ngrams=True)\n",
    "            inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            outputs = model(**inputs).last_hidden_state.detach().cpu().numpy()\n",
    "            embs = np.mean(outputs, axis=1).squeeze()\n",
    "            embs_mean = np.mean(embs, axis=0)\n",
    "\n",
    "            d['texts'].append(texts)\n",
    "            d['embs'].append(embs)\n",
    "            d['embs_mean'].append(embs_mean)\n",
    "\n",
    "    # calculate feature importance for similarity\n",
    "    denominator = calculate_denominator(d['embs_mean'][0], d['embs_mean'][1])\n",
    "    d['imps'].append((d['embs'][0] @ d['embs_mean'][1]) / denominator)\n",
    "    d['imps'].append((d['embs'][1] @ d['embs_mean'][0]) / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223e4a7-6579-48f7-ac72-e1e574bce4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83799434-4120-4ce7-8af5-5a710b923988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35481f-fbf4-4f1b-9ca3-3d787a12081d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
